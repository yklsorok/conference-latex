% participant photo
\photo{images/photo.jpg}

\anumber{N1}

\atitle{SAMPLE TITLE}

\bigskip

\bigskip

\bigskip
\presenting{Author A.\textsuperscript{1}}\authors{, Author B.\textsuperscript{2}, Author C.\textsuperscript{3}}

\affiliation{\textsuperscript{1}Sample institute, sample city, sample country}

\bigskip

\bigskip

\bigskip

\bigskip
\noindent\textbf{The Three Laws of Robotics} (often shortened to \textbf{The Three Laws} or \textbf{Three Laws}) are a set of rules devised by the science fiction author Isaac Asimov and later added to. The rules are introduced in his 1942 short story "Runaround", although they were foreshadowed in a few earlier stories. The Three Laws are:

\begin{enumerate}
\item A robot may not injure a human being or, through inaction, allow a human being to come to harm.
\item A robot must obey the orders given to it by human beings, except where such orders would conflict with the First Law.
\item A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.
\end{enumerate}

These form an organizing principle and unifying theme for Asimov's robotic-based fiction, appearing in his Robot series, the stories linked to it, and his Lucky Starr series of young-adult fiction. The Laws are incorporated into almost all of the positronic robots appearing in his fiction, and cannot be bypassed, being intended as a safety feature. Many of Asimov's robot-focused stories involve robots behaving in unusual and counter-intuitive ways as an intended consequence of how the robot applies the Three Laws to the situation it finds itself in. Other authors working in Asimov's fictional universe have adopted them and references, often parodic, appear throughout science fiction as well as in other genres.

The original laws have been altered and elaborated on by Asimov and other authors. Asimov himself made slight modifications to the first three in various books and short stories to further develop how robots would interact with humans and each other; he also added a fourth, or zeroth law, to precede the others:

    0. A robot may not harm humanity, or, by inaction, allow humanity to come to harm. 
